{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":861220,"sourceType":"datasetVersion","datasetId":454762},{"sourceId":8973033,"sourceType":"datasetVersion","datasetId":5396405}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import wandb\nwandb.login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-30T02:59:25.918639Z","iopub.execute_input":"2024-12-30T02:59:25.919040Z","iopub.status.idle":"2024-12-30T03:06:31.531091Z","shell.execute_reply.started":"2024-12-30T02:59:25.918987Z","shell.execute_reply":"2024-12-30T03:06:31.530269Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install transformers\n!pip install datasets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:06:37.785065Z","iopub.execute_input":"2024-12-30T03:06:37.785982Z","iopub.status.idle":"2024-12-30T03:06:56.417346Z","shell.execute_reply.started":"2024-12-30T03:06:37.785941Z","shell.execute_reply":"2024-12-30T03:06:56.416104Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\n\nimport torch\nfrom torch import nn\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.utils.data.dataset import Dataset, TensorDataset\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom transformers import DistilBertForSequenceClassification, DistilBertTokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:06:56.419503Z","iopub.execute_input":"2024-12-30T03:06:56.419812Z","iopub.status.idle":"2024-12-30T03:07:02.671156Z","shell.execute_reply.started":"2024-12-30T03:06:56.419785Z","shell.execute_reply":"2024-12-30T03:07:02.670490Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def get_device():\n    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndevice = get_device()\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:02.672082Z","iopub.execute_input":"2024-12-30T03:07:02.672492Z","iopub.status.idle":"2024-12-30T03:07:02.697985Z","shell.execute_reply.started":"2024-12-30T03:07:02.672449Z","shell.execute_reply":"2024-12-30T03:07:02.697089Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\nfile_path ='/kaggle/input/vietnamese-sentiment-analyst/data.csv'\n\ndf = pd.read_csv(file_path)\ndf = df[['content', 'label']]\n\nlabels_map = {\n    \"POS\": 0,\n    \"NEU\": 1,\n    \"NEG\": 2\n}\n\ndf['label'] = df['label'].map(labels_map)\ndf = df.dropna(subset=['content'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:02.699094Z","iopub.execute_input":"2024-12-30T03:07:02.699376Z","iopub.status.idle":"2024-12-30T03:07:03.141723Z","shell.execute_reply.started":"2024-12-30T03:07:02.699355Z","shell.execute_reply":"2024-12-30T03:07:03.140680Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport string\n\ndef remove_emoji(text):\n    emoji_pattern = re.compile(\n        \"[\"\n        u\"\\U0001F600-\\U0001F64F\"  \n        u\"\\U0001F300-\\U0001F5FF\"  \n        u\"\\U0001F680-\\U0001F6FF\"  \n        u\"\\U0001F700-\\U0001F77F\"  \n        u\"\\U0001F780-\\U0001F7FF\"  \n        u\"\\U0001F800-\\U0001F8FF\"  \n        u\"\\U0001F900-\\U0001F9FF\"  \n        u\"\\U0001FA00-\\U0001FA6F\"  \n        u\"\\U0001FA70-\\U0001FAFF\"  \n        u\"\\U00002702-\\U000027B0\"  \n        u\"\\U000024C2-\\U0001F251\" \n        \"]+\", flags=re.UNICODE\n    )\n    return emoji_pattern.sub(r'', text)\n\ndef clean_text(text):\n    text = text.lower() \n    text = re.sub(r'[^\\w\\s]', '', text)  \n    text = re.sub(r'\\d+', ' <num> ', text)  \n    text = re.sub(r'\\s+', ' ', text).strip() \n    return text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:03.144095Z","iopub.execute_input":"2024-12-30T03:07:03.144408Z","iopub.status.idle":"2024-12-30T03:07:03.150627Z","shell.execute_reply.started":"2024-12-30T03:07:03.144378Z","shell.execute_reply":"2024-12-30T03:07:03.149653Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:03.151821Z","iopub.execute_input":"2024-12-30T03:07:03.152147Z","iopub.status.idle":"2024-12-30T03:07:03.165735Z","shell.execute_reply.started":"2024-12-30T03:07:03.152118Z","shell.execute_reply":"2024-12-30T03:07:03.164647Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# import pandas as pd\n\n# train_df = pd.read_pickle('/kaggle/input/sentiment-neu-neg/train_augmented.pkl')\n# val_df = pd.read_pickle('/kaggle/input/sentiment-neu-neg/val.pkl')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:03.166778Z","iopub.execute_input":"2024-12-30T03:07:03.167025Z","iopub.status.idle":"2024-12-30T03:07:03.173094Z","shell.execute_reply.started":"2024-12-30T03:07:03.167006Z","shell.execute_reply":"2024-12-30T03:07:03.172257Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_df['content'] = train_df['content'].apply(remove_emoji)  \ntrain_df['content'] = train_df['content'].apply(clean_text)  \n\nval_df['content'] = val_df['content'].apply(remove_emoji)  \nval_df['content'] = val_df['content'].apply(clean_text)  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:03.174218Z","iopub.execute_input":"2024-12-30T03:07:03.174496Z","iopub.status.idle":"2024-12-30T03:07:03.566155Z","shell.execute_reply.started":"2024-12-30T03:07:03.174451Z","shell.execute_reply":"2024-12-30T03:07:03.565452Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_df = train_df[['content', 'label']]\nval_df = val_df[['content', 'label']]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:03.567203Z","iopub.execute_input":"2024-12-30T03:07:03.567486Z","iopub.status.idle":"2024-12-30T03:07:03.575953Z","shell.execute_reply.started":"2024-12-30T03:07:03.567451Z","shell.execute_reply":"2024-12-30T03:07:03.575264Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import DataCollatorWithPadding, AutoTokenizer\n\n# checkpoint = 'distilbert-base-multilingual-cased'\n# tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)\n\ntokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\ndef preprocess_function(examples):\n    return tokenizer(examples[\"content\"], truncation=True, padding = True, max_length = 128)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:03.577053Z","iopub.execute_input":"2024-12-30T03:07:03.577304Z","iopub.status.idle":"2024-12-30T03:07:16.201658Z","shell.execute_reply.started":"2024-12-30T03:07:03.577285Z","shell.execute_reply":"2024-12-30T03:07:16.200876Z"}},"outputs":[{"name":"stderr","text":"2024-12-30 03:07:05.742460: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-12-30 03:07:05.742598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-12-30 03:07:05.880773: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4dfea5b402814cfdae2bf1e0e7f255a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2956117f3ea49828a112da6c93ddf8e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edaffe750a5f42b0bab4162f6e1a9135"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10a97af9b0224ef9b1e2918a26d0cbb4"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train_dataset = Dataset.from_pandas(train_df)\nval_dataset = Dataset.from_pandas(val_df)\n\ntrain_dataset = train_dataset.map(preprocess_function, batched=True)\nval_dataset = val_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:16.202668Z","iopub.execute_input":"2024-12-30T03:07:16.203164Z","iopub.status.idle":"2024-12-30T03:07:18.008465Z","shell.execute_reply.started":"2024-12-30T03:07:16.203141Z","shell.execute_reply":"2024-12-30T03:07:18.007657Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/25148 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d2297bbcfc54394929dc5497b36973d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6288 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fc6414aab2f489e91e25cd6c6444a45"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.009552Z","iopub.execute_input":"2024-12-30T03:07:18.009806Z","iopub.status.idle":"2024-12-30T03:07:18.015244Z","shell.execute_reply.started":"2024-12-30T03:07:18.009786Z","shell.execute_reply":"2024-12-30T03:07:18.014395Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['content', 'label', '__index_level_0__', 'input_ids', 'attention_mask'],\n    num_rows: 25148\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# train_dataset = train_dataset.remove_columns(column_names='content')\n# train_dataset = train_dataset.remove_columns(column_names='__index_level_0__')\n# train_dataset = train_dataset.remove_columns(column_names='attention_mask')\n# val_dataset = val_dataset.remove_columns(column_names='content')\n# val_dataset = val_dataset.remove_columns(column_names='__index_level_0__')\n# val_dataset = val_dataset.remove_columns(column_names='attention_mask')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.016236Z","iopub.execute_input":"2024-12-30T03:07:18.016515Z","iopub.status.idle":"2024-12-30T03:07:18.025945Z","shell.execute_reply.started":"2024-12-30T03:07:18.016466Z","shell.execute_reply":"2024-12-30T03:07:18.024895Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"label\"])\nval_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"label\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.029527Z","iopub.execute_input":"2024-12-30T03:07:18.030310Z","iopub.status.idle":"2024-12-30T03:07:18.038718Z","shell.execute_reply.started":"2024-12-30T03:07:18.030279Z","shell.execute_reply":"2024-12-30T03:07:18.038005Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, collate_fn=data_collator)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=10, collate_fn=data_collator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.039740Z","iopub.execute_input":"2024-12-30T03:07:18.040040Z","iopub.status.idle":"2024-12-30T03:07:18.048863Z","shell.execute_reply.started":"2024-12-30T03:07:18.040014Z","shell.execute_reply":"2024-12-30T03:07:18.048155Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Lặp qua train_loader để xem từng batch\nfor batch in train_loader:\n    # Lặp qua từng mẫu trong batch\n    for key in batch.keys():\n        print(f\"Key: {key}, Shape: {batch[key].shape}\")\n    # Dừng lặp sau 1 batch để chỉ xem 1 lần\n    break  # Bạn có thể loại bỏ break để lặp qua toàn bộ train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.049700Z","iopub.execute_input":"2024-12-30T03:07:18.049919Z","iopub.status.idle":"2024-12-30T03:07:18.111602Z","shell.execute_reply.started":"2024-12-30T03:07:18.049901Z","shell.execute_reply":"2024-12-30T03:07:18.110726Z"}},"outputs":[{"name":"stdout","text":"Key: input_ids, Shape: torch.Size([10, 69])\nKey: attention_mask, Shape: torch.Size([10, 69])\nKey: labels, Shape: torch.Size([10])\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"class MultiLayerBiLSTMModel(nn.Module):\n    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size, max_length, num_layers=2):\n        super(MultiLayerBiLSTMModel, self).__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n        self.num_layers = num_layers\n        self.lstms = nn.ModuleList([\n            nn.LSTM(input_size=embedding_dim if layer == 0 else hidden_size * 2,\n                    hidden_size=hidden_size,\n                    num_layers=1,\n                    bidirectional=True,\n                    batch_first=True)\n            for layer in range(num_layers)\n        ])\n        self.dropout = nn.Dropout(0.3)\n#         self.fc1 = nn.Linear(hidden_size *2, hidden_size)\n#         self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n#         self.fc3 = nn.Linear(hidden_size // 2, output_size)\n        \n        self.fc1 = nn.Linear(hidden_size * 2, 256)\n        self.fc2 = nn.Linear(256, 128)\n        self.fc3 = nn.Linear(128, 64)\n        self.fc4 = nn.Linear(64, output_size)\n    \n        self.relu = nn.ReLU()\n        \n    def forward(self, x):\n        x = x.to(torch.long)\n        x = self.embedding(x)\n        batch_size = x.size(0)\n        \n        for lstm in self.lstms:\n            h0 = torch.zeros(2, batch_size, hidden_size).to(x.device)\n            c0 = torch.zeros(2, batch_size, hidden_size).to(x.device)\n            out, _ = lstm(x, (h0, c0))\n            x = self.dropout(out)\n        \n        # Fully connected layers\n        x = self.relu(self.fc1(x[:, -1, :]))\n        x = self.dropout(x)\n        x = self.relu(self.fc2(x))\n        x = self.dropout(x)\n        x = self.relu(self.fc3(x))\n        x = self.dropout(x)\n        x = self.fc4(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.112823Z","iopub.execute_input":"2024-12-30T03:07:18.113446Z","iopub.status.idle":"2024-12-30T03:07:18.123363Z","shell.execute_reply.started":"2024-12-30T03:07:18.113413Z","shell.execute_reply":"2024-12-30T03:07:18.122536Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# HYPER PARAMS\nvocab_size = tokenizer.vocab_size\nembedding_dim = 128\nhidden_size = 128\noutput_size = 3\nmax_length = 128\nnum_epochs = 100\nlr = 0.001\nnum_layers = 1\ndevice = device\nsave_best_model_path = 'best_lstm_model.pt'\nprint(f\"Vocabulary size: {vocab_size}\")\nprint(f\"Embedding dimension: {embedding_dim}\")\nprint(f\"Hidden size: {hidden_size}\")\nprint(f\"Output size: {output_size}\")\nprint(f\"Max length: {max_length}\")\nprint(f\"Number of epochs: {num_epochs}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.124552Z","iopub.execute_input":"2024-12-30T03:07:18.124885Z","iopub.status.idle":"2024-12-30T03:07:18.138890Z","shell.execute_reply.started":"2024-12-30T03:07:18.124856Z","shell.execute_reply":"2024-12-30T03:07:18.137977Z"}},"outputs":[{"name":"stdout","text":"Vocabulary size: 36096\nEmbedding dimension: 128\nHidden size: 128\nOutput size: 3\nMax length: 128\nNumber of epochs: 100\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport wandb\n\ndef train(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=10, \n          save_best_model_path=None, save_last_model_path=None):\n    \n    best_val_loss = float('inf')\n    best_val_accu = 0\n    \n    for epoch in range(num_epochs):\n        model.train()\n        running_train_loss = 0.0\n        correct_predictions = 0\n        total_predictions = 0\n        \n        # Training loop\n        for i, batch in enumerate(train_loader):\n            inputs, labels = batch['input_ids'], batch['labels'] \n            \n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            \n            loss.backward()\n            optimizer.step()\n            \n            running_train_loss += loss.item()\n            \n            # Calculate accuracy\n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n        \n        # Calculate average train loss and accuracy for the epoch\n        train_loss = running_train_loss / len(train_loader)\n        train_accuracy = correct_predictions / total_predictions\n        \n        # Log training metrics\n        wandb.log({\"Train Loss\": train_loss, \"Train Accuracy\": train_accuracy})\n        \n        # Validation loop\n        model.eval()\n        running_val_loss = 0.0\n        correct_val_predictions = 0\n        total_val_predictions = 0\n        \n        with torch.no_grad():\n            for batch in val_loader:\n                inputs, labels = batch['input_ids'], batch['labels']\n                inputs, labels = inputs.to(device), labels.to(device)\n\n                outputs = model(inputs)\n                val_loss = criterion(outputs, labels)\n                running_val_loss += val_loss.item()\n\n                _, predicted = torch.max(outputs, 1)\n                correct_val_predictions += (predicted == labels).sum().item()\n                total_val_predictions += labels.size(0)\n\n        # Calculate average validation loss and accuracy\n        val_loss = running_val_loss / len(val_loader)\n        val_accuracy = correct_val_predictions / total_val_predictions\n        \n        # Log validation metrics\n        wandb.log({\"Val Loss\": val_loss, \"Val Accuracy\": val_accuracy})\n        \n        # Print epoch statistics\n        print(f\"Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, \\\n              Val Loss: {val_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n        \n        # Save best model\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_val_accu = val_accuracy\n            best_model_state_dict = model.state_dict()\n            if save_best_model_path:\n                torch.save(best_model_state_dict, save_best_model_path)\n                print(\"Model saved\")\n        \n    # Save last model\n    if save_last_model_path:\n        torch.save(model.state_dict(), save_last_model_path)\n        \n    print(f\"Training finished. Best val accuracy is: {best_val_accu}\")\n    wandb.finish()  # Finish wandb session\n    \n    return best_model_state_dict, best_val_accu\n\n# Evaluation function (for validation and testing)\ndef evaluate(model, loader, criterion, device):\n    model.eval()\n    correct_predictions = 0\n    total_predictions = 0\n    running_val_loss = 0.0\n    \n    with torch.no_grad():\n        for i, batch in enumerate(loader):\n            inputs, labels = batch['input_ids'], batch['labels']\n            \n            inputs, labels = inputs.to(device), labels.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            running_val_loss += loss.item()\n            \n            _, predicted = torch.max(outputs, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n    \n    val_loss = running_val_loss / len(loader)\n    val_accuracy = correct_predictions / total_predictions\n    \n    return val_loss, val_accuracy\n\n# Example usage:\n# Initialize your model, optimizer, criterion, and data loaders\n# Then call train function passing all required parameters\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.140251Z","iopub.execute_input":"2024-12-30T03:07:18.140529Z","iopub.status.idle":"2024-12-30T03:07:18.157092Z","shell.execute_reply.started":"2024-12-30T03:07:18.140507Z","shell.execute_reply":"2024-12-30T03:07:18.156235Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"model = MultiLayerBiLSTMModel(vocab_size, embedding_dim, hidden_size, output_size, max_length, num_layers).to(device)\noptimizer = optim.Adam(model.parameters(), lr=lr)\ncriterion = nn.CrossEntropyLoss()\nwandb.init(\n      project=\"lstm_sentiment_analysis\", \n      name=f\"wandb_example\", \n      # Track hyperparameters and run metadata\n      config={\n      \"learning_rate\": lr,\n      \"architecture\": \"LSTM\",\n      \"dataset\": \"vsa\",\n      \"epochs\": num_epochs,\n      })\nwandb.watch(model)\ntrain(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=num_epochs)\n\nwandb.finish()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-30T03:07:18.158308Z","iopub.execute_input":"2024-12-30T03:07:18.158837Z","execution_failed":"2024-12-30T03:08:31.050Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvuminhhoang-vnu\u001b[0m (\u001b[33mvuminhhoang1512\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.19.1 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.0"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241230_030718-4ha8l9ct</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/vuminhhoang1512/lstm_sentiment_analysis/runs/4ha8l9ct' target=\"_blank\">wandb_example</a></strong> to <a href='https://wandb.ai/vuminhhoang1512/lstm_sentiment_analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/vuminhhoang1512/lstm_sentiment_analysis' target=\"_blank\">https://wandb.ai/vuminhhoang1512/lstm_sentiment_analysis</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/vuminhhoang1512/lstm_sentiment_analysis/runs/4ha8l9ct' target=\"_blank\">https://wandb.ai/vuminhhoang1512/lstm_sentiment_analysis/runs/4ha8l9ct</a>"},"metadata":{}},{"name":"stdout","text":"Epoch [1/100], Train Loss: 0.9064,               Val Loss: 0.9142, Train Accuracy: 0.6412, Val Accuracy: 0.6279\nEpoch [2/100], Train Loss: 0.8983,               Val Loss: 0.9152, Train Accuracy: 0.6414, Val Accuracy: 0.6279\nEpoch [3/100], Train Loss: 0.8972,               Val Loss: 0.9156, Train Accuracy: 0.6416, Val Accuracy: 0.6277\n","output_type":"stream"}],"execution_count":null}]}